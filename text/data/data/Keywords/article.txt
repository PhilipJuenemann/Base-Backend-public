LeCun, who is chief scientist at Meta’s AI lab and a professor at New York University, is one of the most influential AI researchers in the world. He had been trying to give machines a basic grasp of how the world works a kind of common sense by training neural networks to predict what was going to happen next in video clips of everyday events. But guessing future frames of a video pixel by pixel was just too complex. He hit a wall. Now, after months figuring out what was missing, he has a bold new vision for the next generation of AI. In a draft document shared with MIT Technology Review, LeCun sketches out an approach that he thinks will one day give machines the common sense they need to navigate the world. (Update: LeCun has since posted the document online.) For LeCun, the proposals could be the first steps on a path to building machines with the ability to reason and plan like humans what many call artificial general intelligence, or AGI. He also steps away from today’s hottest trends in machine learning, resurrecting some old ideas that have gone out of fashion. But his vision is far from comprehensive; indeed, it may raise more questions than it answers. The biggest question mark, as LeCun points out himself, is that he does not know how to build what he describes. The centerpiece of the new approach is a neural network that can learn to view the world at different levels of detail. Ditching the need for pixel-perfect predictions, this network would focus only on those features in a scene that are relevant for the task at hand. LeCun proposes pairing this core network with another, called the configurator, which determines what level of detail is required and tweaks the overall system accordingly. For LeCun, AGI is going to be a part of how we interact with future tech. His vision is colored by that of his employer, Meta, which is pushing a virtual-reality metaverse. He says that in 10 or 15 years people won’t be carrying smartphones in their pockets, but augmented-reality glasses fitted with virtual assistants that will guide humans through their day. “For those to be most useful to us, they basically have to have more or less human-level intelligence,” he says. “Yann has been talking about many of these ideas for some time,” says Yoshua Bengio, an AI researcher at the University of Montreal and scientific director at the Mila-Quebec Institute. “But it is good to see it all together, in one big picture.” Bengio thinks that LeCun asks the right questions. He also thinks it’s great that LeCun is willing to put out a document that has so few answers. It’s a research proposal rather than a set of clean results, he says. “People talk about these things in private, but they’re not usually shared publicly,” says Bengio. “It’s risky.”
